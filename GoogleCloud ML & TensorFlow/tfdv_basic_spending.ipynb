{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow Data Validation\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Review TFDV methods\n",
    "2. Generate statistics\n",
    "3. Visualize statistics\n",
    "4. Infer a schema\n",
    "5. Update a schema\n",
    "\n",
    "\n",
    "\n",
    "## Introduction \n",
    "This lab is an introduction to TensorFlow Data Validation (TFDV), a key component of TensorFlow Extended.  This lab serves as a foundation for understanding the features of TFDV and how it can help you understand, validate, and monitor your data. \n",
    "\n",
    "TFDV can be used for generating schemas and statistics about the distribution of every feature in the dataset. Such information is useful for comparing multiple datasets (e.g. training vs inference datasets) and reporting:\n",
    "\n",
    "Statistical differences in the features distribution\n",
    "TFDV also offers visualization capabilities for comparing datasets based on the Google PAIR Facets project.  \n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review the [Solution Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/production_ml/solutions/tfdv_basic_spending.ipynb) for reference. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsHg6SD2nO1v"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsHg6SD2nO1v"
   },
   "source": [
    "**Run the below cell. Restart the kernel (Kernel > Restart kernel > Restart).**\n",
    "**Re-run the below cell and proceed further.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow==2.0.0\n",
      "  Downloading pyarrow-2.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.7 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.7/site-packages (from pyarrow==2.0.0) (1.19.5)\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 5.0.0\n",
      "    Uninstalling pyarrow-5.0.0:\n",
      "      Successfully uninstalled pyarrow-5.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 1.3.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\n",
      "tfx-bsl 1.3.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.22.0 which is incompatible.\n",
      "tensorflow-transform 1.3.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\n",
      "apache-beam 2.32.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\n",
      "apache-beam 2.32.0 requires typing-extensions<3.8.0,>=3.7.0, but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\n",
      "Successfully installed pyarrow-2.0.0\n",
      "Collecting numpy==1.19.2\n",
      "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.18.0 requires tensorflow-io-gcs-filesystem==0.18.0, which is not installed.\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\n",
      "tfx-bsl 1.3.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\n",
      "tfx-bsl 1.3.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.22.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires tensorboard~=2.6, but you have tensorboard 2.5.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
      "tensorflow-transform 1.3.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\n",
      "tensorflow-io 0.18.0 requires tensorflow<2.6.0,>=2.5.0, but you have tensorflow 2.6.0 which is incompatible.\n",
      "apache-beam 2.32.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\n",
      "apache-beam 2.32.0 requires typing-extensions<3.8.0,>=3.7.0, but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.19.2\n",
      "Collecting tensorflow-data-validation\n",
      "  Downloading tensorflow_data_validation-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (2.6.0)\n",
      "Requirement already satisfied: tensorflow-metadata<1.3,>=1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (1.2.0)\n",
      "Requirement already satisfied: pyarrow<3,>=1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (2.0.0)\n",
      "Requirement already satisfied: pandas<2,>=1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (1.3.3)\n",
      "Collecting joblib<0.15,>=0.12\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 58.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.20,>=1.16 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (1.19.2)\n",
      "Requirement already satisfied: six<2,>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (1.16.0)\n",
      "Requirement already satisfied: tfx-bsl<1.4,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (1.3.0)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.32 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (2.32.0)\n",
      "Collecting absl-py<0.13,>=0.9\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 54.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation) (3.18.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (3.12.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2021.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2.25.1)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 52.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.38.1)\n",
      "Requirement already satisfied: avro-python3!=1.9.2,<1.10.0,>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.9.2.1)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (3.6.3)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.4.4)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.19.1)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.4.2)\n",
      "Collecting typing-extensions<3.8.0,>=3.7.0\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (4.1.3)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.7)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.18.2)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2.6.0)\n",
      "Collecting google-cloud-bigtable<2,>=0.31.1\n",
      "  Downloading google_cloud_bigtable-1.7.0-py2.py3-none-any.whl (267 kB)\n",
      "\u001b[K     |████████████████████████████████| 267 kB 60.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio-gcp<1,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.2.2)\n",
      "Requirement already satisfied: google-cloud-dlp<2,>=0.12.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.0.0)\n",
      "Collecting google-cloud-language<2,>=1.3.0\n",
      "  Downloading google_cloud_language-1.3.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 2.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-videointelligence<2,>=1.8.0\n",
      "  Downloading google_cloud_videointelligence-1.16.1-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 56.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<2,>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.35.0)\n",
      "Collecting google-cloud-datastore<2,>=1.8.0\n",
      "  Downloading google_cloud_datastore-1.15.3-py2.py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 55.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools<5,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (4.2.2)\n",
      "Collecting google-cloud-vision<2,>=0.38.0\n",
      "  Downloading google_cloud_vision-1.0.0-py2.py3-none-any.whl (435 kB)\n",
      "\u001b[K     |████████████████████████████████| 435 kB 84.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-cloud-recommendations-ai<=0.2.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.2.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2.26.0)\n",
      "Requirement already satisfied: google-cloud-pubsub<2,>=0.39.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.7.0)\n",
      "Collecting google-cloud-spanner<2,>=1.13.0\n",
      "  Downloading google_cloud_spanner-1.19.1-py2.py3-none-any.whl (255 kB)\n",
      "\u001b[K     |████████████████████████████████| 255 kB 82.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-core<2,>=0.28.1\n",
      "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.5.31)\n",
      "Requirement already satisfied: fasteners>=0.14 in /opt/conda/lib/python3.7/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.16.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (4.7.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (58.0.4)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.31.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2.0.3)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.19.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.53.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.12.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.2.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<0.20.0,>=0.8->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2.4.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.32->tensorflow-data-validation) (1.26.6)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (1.6.3)\n",
      "Requirement already satisfied: keras~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (2.6.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (1.1.0)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 73.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-estimator~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (3.3.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (0.4.0)\n",
      "Requirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (0.37.0)\n",
      "Collecting six<2,>=1.12\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (1.12)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (4.8.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (3.1.1)\n",
      "Collecting google-api-python-client<2,>=1.7.11\n",
      "  Downloading google_api_python_client-1.12.8-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 39 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15 in /opt/conda/lib/python3.7/site-packages (from tfx-bsl<1.4,>=1.3.0->tensorflow-data-validation) (2.6.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.4,>=1.3.0->tensorflow-data-validation) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.4,>=1.3.0->tensorflow-data-validation) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2->tensorflow-data-validation) (3.5.0)\n",
      "Building wheels for collected packages: dill\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=1c3a015bd81fff38745236109d8de2341bc24e17d0eeac15e3db9b490b01e203\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
      "Successfully built dill\n",
      "Installing collected packages: typing-extensions, six, absl-py, tensorboard, google-cloud-core, dill, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-language, google-cloud-datastore, google-cloud-bigtable, google-api-python-client, joblib, tensorflow-data-validation\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.14.0\n",
      "    Uninstalling absl-py-0.14.0:\n",
      "      Successfully uninstalled absl-py-0.14.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: google-cloud-core\n",
      "    Found existing installation: google-cloud-core 2.0.0\n",
      "    Uninstalling google-cloud-core-2.0.0:\n",
      "      Successfully uninstalled google-cloud-core-2.0.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "  Attempting uninstall: google-cloud-vision\n",
      "    Found existing installation: google-cloud-vision 2.4.2\n",
      "    Uninstalling google-cloud-vision-2.4.2:\n",
      "      Successfully uninstalled google-cloud-vision-2.4.2\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 2.3.2\n",
      "    Uninstalling google-cloud-videointelligence-2.3.2:\n",
      "      Successfully uninstalled google-cloud-videointelligence-2.3.2\n",
      "  Attempting uninstall: google-cloud-spanner\n",
      "    Found existing installation: google-cloud-spanner 3.10.0\n",
      "    Uninstalling google-cloud-spanner-3.10.0:\n",
      "      Successfully uninstalled google-cloud-spanner-3.10.0\n",
      "  Attempting uninstall: google-cloud-language\n",
      "    Found existing installation: google-cloud-language 2.2.2\n",
      "    Uninstalling google-cloud-language-2.2.2:\n",
      "      Successfully uninstalled google-cloud-language-2.2.2\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 2.1.6\n",
      "    Uninstalling google-cloud-datastore-2.1.6:\n",
      "      Successfully uninstalled google-cloud-datastore-2.1.6\n",
      "  Attempting uninstall: google-cloud-bigtable\n",
      "    Found existing installation: google-cloud-bigtable 2.3.3\n",
      "    Uninstalling google-cloud-bigtable-2.3.3:\n",
      "      Successfully uninstalled google-cloud-bigtable-2.3.3\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 2.22.0\n",
      "    Uninstalling google-api-python-client-2.22.0:\n",
      "      Successfully uninstalled google-api-python-client-2.22.0\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.18.0 requires tensorflow-io-gcs-filesystem==0.18.0, which is not installed.\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\n",
      "tensorflow-io 0.18.0 requires tensorflow<2.6.0,>=2.5.0, but you have tensorflow 2.6.0 which is incompatible.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.8 which is incompatible.\n",
      "black 21.9b0 requires typing-extensions>=3.10.0.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.12.0 dill-0.3.1.1 google-api-python-client-1.12.8 google-cloud-bigtable-1.7.0 google-cloud-core-1.7.2 google-cloud-datastore-1.15.3 google-cloud-language-1.3.0 google-cloud-spanner-1.19.1 google-cloud-videointelligence-1.16.1 google-cloud-vision-1.0.0 joblib-0.14.1 six-1.15.0 tensorboard-2.6.0 tensorflow-data-validation-1.3.0 typing-extensions-3.7.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow==2.0.0\n",
    "!pip install numpy==1.19.2\n",
    "!pip install tensorflow-data-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing TensorFlow Data Validation\n",
      "TFDV version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow_data_validation as tfdv\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Installing TensorFlow Data Validation')\n",
    "!pip install -q tensorflow_data_validation[visualization]\n",
    "\n",
    "print('TFDV version: {}'.format(tfdv.version.__version__))\n",
    "# Confirm that we're using Python 3\n",
    "assert sys.version_info.major is 3, 'Oops, not running Python 3. Use Runtime > Change runtime type'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fnm6Mj3vTGLm"
   },
   "source": [
    "###  Load the Consumer Spending Dataset\n",
    "\n",
    "We will download our dataset from Google Cloud Storage. The columns in the dataset are:\n",
    "\n",
    "* 'Graduated': Whether or not the person is a college graduate\n",
    "* 'Work Experience': The number of years in the workforce\n",
    "* 'Family Size': The size of the family unit\n",
    "* 'Spending Score': The spending score for consumer spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Spending_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Graduated     Profession  Work_Experience  Family_Size Spending_Score\n",
       "0        No     Healthcare              1.0          4.0            Low\n",
       "1       Yes       Engineer              NaN          3.0        Average\n",
       "2       Yes       Engineer              1.0          1.0            Low\n",
       "3       Yes         Lawyer              0.0          2.0           High\n",
       "4       Yes  Entertainment              NaN          6.0           High"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a comma-separated values (csv) file into DataFrame.\n",
    "# TODO: Your code goes here\n",
    "score_train = pd.read_csv('data/score_train.csv')\n",
    "score_train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Spending_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Executive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Graduated     Profession  Work_Experience  Family_Size Spending_Score\n",
       "0        No         Doctor              0.0          5.0        Average\n",
       "1       Yes  Entertainment              1.0          4.0        Average\n",
       "2        No         Lawyer              0.0          5.0            Low\n",
       "3       Yes      Executive              1.0          5.0           High\n",
       "4       Yes         Artist              1.0          2.0        Average"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a comma-separated values (csv) file into DataFrame.\n",
    "# TODO: Your code goes here\n",
    "score_test = pd.read_csv('data/score_test.csv')\n",
    "score_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Graduated        3964 non-null   object \n",
      " 1   Profession       3944 non-null   object \n",
      " 2   Work_Experience  3589 non-null   float64\n",
      " 3   Family_Size      3831 non-null   float64\n",
      " 4   Spending_Score   4000 non-null   object \n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "score_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the methods present in TFDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CombinerStatsGenerator',\n",
       " 'FeaturePath',\n",
       " 'GenerateStatistics',\n",
       " 'StatsOptions',\n",
       " 'TransformStatsGenerator',\n",
       " 'WriteStatisticsToBinaryFile',\n",
       " 'WriteStatisticsToTFRecord',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'anomalies',\n",
       " 'api',\n",
       " 'arrow',\n",
       " 'coders',\n",
       " 'compare_slices',\n",
       " 'constants',\n",
       " 'display_anomalies',\n",
       " 'display_schema',\n",
       " 'experimental_get_feature_value_slicer',\n",
       " 'generate_statistics_from_csv',\n",
       " 'generate_statistics_from_dataframe',\n",
       " 'generate_statistics_from_tfrecord',\n",
       " 'get_domain',\n",
       " 'get_feature',\n",
       " 'get_feature_stats',\n",
       " 'get_slice_stats',\n",
       " 'infer_schema',\n",
       " 'load_anomalies_text',\n",
       " 'load_schema_text',\n",
       " 'load_statistics',\n",
       " 'load_stats_binary',\n",
       " 'load_stats_text',\n",
       " 'pywrap',\n",
       " 'set_domain',\n",
       " 'statistics',\n",
       " 'types',\n",
       " 'update_schema',\n",
       " 'utils',\n",
       " 'validate_examples_in_csv',\n",
       " 'validate_examples_in_tfrecord',\n",
       " 'validate_statistics',\n",
       " 'version',\n",
       " 'visualize_statistics',\n",
       " 'write_anomalies_text',\n",
       " 'write_schema_text',\n",
       " 'write_stats_text']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check methods present in tfdv\n",
    "# TODO: Your code goes here\n",
    "[methods for methods in dir(tfdv)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing data with TFDV\n",
    "The usual workflow when using TFDV during training is as follows:\n",
    "\n",
    "\n",
    "1.   Generate statistics for the data\n",
    "2.   Use those statistics to generate a schema for each feature\n",
    "3.   Visualize the schema and statistics and manually inspect them\n",
    "4.   Update the schema if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and visualize statistics\n",
    "\n",
    "First we'll use [`tfdv.generate_statistics_from_csv`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_csv) to compute statistics for our training data. (ignore the snappy warnings)\n",
    "\n",
    "TFDV can compute descriptive [statistics](https://github.com/tensorflow/metadata/blob/v0.6.0/tensorflow_metadata/proto/v0/statistics.proto) that provide a quick overview of the data in terms of the features that are present and the shapes of their value distributions.\n",
    "\n",
    "Internally, TFDV uses [Apache Beam](https://beam.apache.org/)'s data-parallel processing framework to scale the computation of statistics over large datasets. For applications that wish to integrate deeper with TFDV (e.g., attach statistics generation at the end of a data-generation pipeline), the API also exposes a Beam PTransform for statistics generation.\n",
    "\n",
    "**NOTE:  Compute statistics**\n",
    "* [tfdv.generate_statistics_from_csv](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_csv)\n",
    "* [tfdv.generate_statistics_from_dataframe](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_dataframe)\n",
    "* [tfdv.generate_statistics_from_tfrecord](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_tfrecord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Statistics from a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute data statistics for the input pandas DataFrame.\n",
    "# TODO: Your code goes here\n",
    "stats = tfdv.generate_statistics_from_dataframe(dataframe=score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use [`tfdv.visualize_statistics`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/visualize_statistics), which uses [Facets](https://pair-code.github.io/facets/) to create a succinct visualization of our training data:\n",
    "\n",
    "* Notice that numeric features and categorical features are visualized separately, and that charts are displayed showing the distributions for each feature.\n",
    "* Notice that features with missing or zero values display a percentage in red as a visual indicator that there may be issues with examples in those features.  The percentage is the percentage of examples that have missing or zero values for that feature.\n",
    "* Notice that there are no examples with values for `pickup_census_tract`.  This is an opportunity for dimensionality reduction!\n",
    "* Try clicking \"expand\" above the charts to change the display\n",
    "* Try hovering over bars in the charts to display bucket ranges and counts\n",
    "* Try switching between the log and linear scales, and notice how the log scale reveals much more detail about the `payment_type` categorical feature\n",
    "* Try selecting \"quantiles\" from the \"Chart to show\" menu, and hover over the markers to show the quantile percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the input statistics using Facets.\n",
    "# TODO: Your code goes here\n",
    "tfdv.visualize_statistics(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFDV generates different types of statistics based on the type of features.\n",
    "\n",
    "**For numerical features, TFDV computes for every feature:**\n",
    "* Count of records\n",
    "* Number of missing (i.e. null values)\n",
    "* Histogram of values\n",
    "* Mean and standard deviation\n",
    "* Minimum and maximum values\n",
    "* Percentage of zero values\n",
    "\n",
    "**For categorical features, TFDV provides:**\n",
    "* Count of values\n",
    "* Percentage of missing values\n",
    "* Number of unique values\n",
    "* Average string length\n",
    "* Count for each label and its rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare the score_train and the score_test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_stats = tfdv.generate_statistics_from_dataframe(dataframe=score_train)\n",
    "test_stats = tfdv.generate_statistics_from_dataframe(dataframe=score_test)\n",
    "\n",
    "tfdv.visualize_statistics(\n",
    "  lhs_statistics=train_stats, lhs_name='TRAIN_DATASET',\n",
    "  rhs_statistics=test_stats, rhs_name='NEW_DATASET')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVR02-y4V0uM"
   },
   "source": [
    "### Infer a schema\n",
    "\n",
    "Now let's use [`tfdv.infer_schema`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/infer_schema) to create a schema for our data.  A schema defines constraints for the data that are relevant for ML. Example constraints include the data type of each feature, whether it's numerical or categorical, or the frequency of its presence in the data.  For categorical features the schema also defines the domain - the list of acceptable values.  Since writing a schema can be a tedious task, especially for datasets with lots of features, TFDV provides a method to generate an initial version of the schema based on the descriptive statistics.\n",
    "\n",
    "Getting the schema right is important because the rest of our production pipeline will be relying on the schema that TFDV generates to be correct.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Schema\n",
    "Once statistics are generated, the next step is to generate a schema for our dataset. This schema will map each feature in the dataset to a type (float, bytes, etc.). Also define feature boundaries (min, max, distribution of values and missings, etc.).\n",
    "\n",
    "Link to infer schema\n",
    "https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/infer_schema\n",
    "\n",
    "With TFDV, we generate schema from statistics using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LLkRJThVr9m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature {\n",
      "  name: \"Graduated\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: BYTES\n",
      "  domain: \"Graduated\"\n",
      "  presence {\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Profession\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: BYTES\n",
      "  domain: \"Profession\"\n",
      "  presence {\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Work_Experience\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Family_Size\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Spending_Score\"\n",
      "  type: BYTES\n",
      "  domain: \"Spending_Score\"\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "  shape {\n",
      "    dim {\n",
      "      size: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "string_domain {\n",
      "  name: \"Graduated\"\n",
      "  value: \"No\"\n",
      "  value: \"Yes\"\n",
      "}\n",
      "string_domain {\n",
      "  name: \"Profession\"\n",
      "  value: \"Artist\"\n",
      "  value: \"Doctor\"\n",
      "  value: \"Engineer\"\n",
      "  value: \"Entertainment\"\n",
      "  value: \"Executive\"\n",
      "  value: \"Healthcare\"\n",
      "  value: \"Homemaker\"\n",
      "  value: \"Lawyer\"\n",
      "  value: \"Marketing\"\n",
      "}\n",
      "string_domain {\n",
      "  name: \"Spending_Score\"\n",
      "  value: \"Average\"\n",
      "  value: \"High\"\n",
      "  value: \"Low\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Infers schema from the input statistics.\n",
    "# TODO: Your code goes here\n",
    "schema = tfdv.infer_schema(statistics=stats)\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema also provides documentation for the data, and so is useful when different developers work on the same data.  Let's use [`tfdv.display_schema`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/display_schema) to display the inferred schema so that we can review it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Graduated'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>'Graduated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Profession'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>'Profession'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Work_Experience'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Family_Size'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Spending_Score'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'Spending_Score'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Type  Presence Valency            Domain\n",
       "Feature name                                                 \n",
       "'Graduated'        STRING  optional  single       'Graduated'\n",
       "'Profession'       STRING  optional  single      'Profession'\n",
       "'Work_Experience'   FLOAT  optional  single                 -\n",
       "'Family_Size'       FLOAT  optional  single                 -\n",
       "'Spending_Score'   STRING  required          'Spending_Score'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domain</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Graduated'</th>\n",
       "      <td>'No', 'Yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Profession'</th>\n",
       "      <td>'Artist', 'Doctor', 'Engineer', 'Entertainment', 'Executive', 'Healthcare', 'Homemaker', 'Lawyer', 'Marketing'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Spending_Score'</th>\n",
       "      <td>'Average', 'High', 'Low'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          Values\n",
       "Domain                                                                                                                          \n",
       "'Graduated'       'No', 'Yes'                                                                                                   \n",
       "'Profession'      'Artist', 'Doctor', 'Engineer', 'Entertainment', 'Executive', 'Healthcare', 'Homemaker', 'Lawyer', 'Marketing'\n",
       "'Spending_Score'  'Average', 'High', 'Low'                                                                                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfdv.display_schema(schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFDV provides a API to print a summary of each feature schema using\n",
    "\n",
    "In this visualization, the columns stand for:\n",
    "\n",
    "**Type** indicates the feature datatype.\n",
    "\n",
    "**Presence** indicates whether the feature must be present in 100% of examples (required) or not (optional).\n",
    "\n",
    "**Valency** indicates the number of values required per training example. \n",
    "\n",
    "**Domain and Values** indicates The feature domain and its values\n",
    "\n",
    "In the case of categorical features, single indicates that each training example must have exactly one category for the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the Schema \n",
    "As stated above, **Presence** indicates whether the feature must be present in 100% of examples (required) or not (optional).  Currently, all of our features except for our target label are shown as \"optional\". We need to make our features all required except for \"Work Experience\".  We will need to update the schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFDV lets you update the schema according to your domain knowledge of the data if you are not satisfied by the auto-generated schema.  We will update three use cases:  Making a feature required, adding a value to a feature, and change a feature from a float to an integer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change optional features to required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Family_Size from FLOAT to Int\n",
    "Graduated_feature = tfdv.get_feature(schema, 'Graduated')\n",
    "Graduated_feature.presence.min_fraction = 1.0\n",
    "Profession_feature = tfdv.get_feature(schema, 'Profession')\n",
    "Profession_feature.presence.min_fraction = 1.0\n",
    "Family_Size_feature = tfdv.get_feature(schema, 'Family_Size')\n",
    "Family_Size_feature.presence.min_fraction = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Graduated'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>'Graduated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Profession'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>'Profession'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Work_Experience'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Family_Size'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Spending_Score'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'Spending_Score'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Type  Presence Valency            Domain\n",
       "Feature name                                                 \n",
       "'Graduated'        STRING  required  single  'Graduated'     \n",
       "'Profession'       STRING  required  single  'Profession'    \n",
       "'Work_Experience'  FLOAT   optional  single  -               \n",
       "'Family_Size'      FLOAT   required  single  -               \n",
       "'Spending_Score'   STRING  required          'Spending_Score'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domain</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Graduated'</th>\n",
       "      <td>'No', 'Yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Profession'</th>\n",
       "      <td>'Artist', 'Doctor', 'Engineer', 'Entertainment', 'Executive', 'Healthcare', 'Homemaker', 'Lawyer', 'Marketing'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Spending_Score'</th>\n",
       "      <td>'Average', 'High', 'Low'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          Values\n",
       "Domain                                                                                                                          \n",
       "'Graduated'       'No', 'Yes'                                                                                                   \n",
       "'Profession'      'Artist', 'Doctor', 'Engineer', 'Entertainment', 'Executive', 'Healthcare', 'Homemaker', 'Lawyer', 'Marketing'\n",
       "'Spending_Score'  'Average', 'High', 'Low'                                                                                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfdv.display_schema(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update a feature with a new value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add \"self-employed\" to the Profession feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self-Employed', 'Artist', 'Doctor', 'Engineer', 'Entertainment', 'Executive', 'Healthcare', 'Homemaker', 'Lawyer', 'Marketing']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Profession_domain = tfdv.get_domain(schema, 'Profession')\n",
    "Profession_domain.value.insert(0, 'Self-Employed')\n",
    "Profession_domain.value\n",
    "# [0 indicates I want 'Self-Employed to come first', if the number were 3, \n",
    "# it would be placed after the third value. ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove \"Homemaker\" from \"Profession\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Profession_domain = tfdv.get_domain(schema, 'Profession')\n",
    "Profession_domain.value.remove('Homemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self-Employed', 'Artist', 'Doctor', 'Engineer', 'Entertainment', 'Executive', 'Healthcare', 'Lawyer', 'Marketing']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Profession_domain.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change a feature from a float to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Family_Size to Int\n",
    "size = tfdv.get_feature(schema, 'Family_Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Graduated'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>'Graduated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Profession'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>'Profession'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Work_Experience'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Family_Size'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Spending_Score'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'Spending_Score'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Type  Presence Valency            Domain\n",
       "Feature name                                                 \n",
       "'Graduated'        STRING  required  single  'Graduated'     \n",
       "'Profession'       STRING  required  single  'Profession'    \n",
       "'Work_Experience'  FLOAT   optional  single  -               \n",
       "'Family_Size'      INT     required  single  -               \n",
       "'Spending_Score'   STRING  required          'Spending_Score'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domain</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Graduated'</th>\n",
       "      <td>'No', 'Yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Profession'</th>\n",
       "      <td>'Self-Employed', 'Artist', 'Doctor', 'Engineer', 'Entertainment', 'Executive', 'Healthcare', 'Lawyer', 'Marketing'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'Spending_Score'</th>\n",
       "      <td>'Average', 'High', 'Low'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              Values\n",
       "Domain                                                                                                                              \n",
       "'Graduated'       'No', 'Yes'                                                                                                       \n",
       "'Profession'      'Self-Employed', 'Artist', 'Doctor', 'Engineer', 'Entertainment', 'Executive', 'Healthcare', 'Lawyer', 'Marketing'\n",
       "'Spending_Score'  'Average', 'High', 'Low'                                                                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size.type=2\n",
    "tfdv.display_schema(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next lab, you compare two datasets and check for anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8eC59yISdGB"
   },
   "source": [
    "## When to use TFDV\n",
    "\n",
    "It's easy to think of TFDV as only applying to the start of your training pipeline, as we did here, but in fact it has many uses. Here are a few more:\n",
    "\n",
    "* Validating new data for inference to make sure that we haven't suddenly started receiving bad features\n",
    "* Validating new data for inference to make sure that our model has trained on that part of the decision surface\n",
    "* Validating our data after we've transformed it and done feature engineering (probably using [TensorFlow Transform](https://www.tensorflow.org/tfx/transform/)) to make sure we haven't done something wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/GoogleCloudPlatform/mlops-on-gcp/blob/master/examples/tfdv-structured-data/tfdv-covertype.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "tghWegsjhpkt"
   ],
   "name": "tfdv_basic.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-6.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
